<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Guide Visuel des R√©seaux de Neurones</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Inter', sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background: white;
            margin-top: 20px;
            margin-bottom: 20px;
            border-radius: 15px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
        }

        .header {
            text-align: center;
            margin-bottom: 40px;
            padding: 30px 0;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border-radius: 15px;
        }

        .header h1 {
            font-size: 2.5em;
            font-weight: 700;
            margin-bottom: 10px;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }

        .header p {
            font-size: 1.2em;
            opacity: 0.9;
        }

        .toc {
            background: #f8f9fa;
            padding: 25px;
            border-radius: 10px;
            margin-bottom: 30px;
            border-left: 5px solid #667eea;
        }

        .toc h2 {
            color: #667eea;
            margin-bottom: 15px;
            font-size: 1.5em;
        }

        .toc ul {
            list-style: none;
            padding-left: 20px;
        }

        .toc li {
            margin-bottom: 8px;
            padding-left: 20px;
            position: relative;
        }

        .toc li::before {
            content: "‚ñ∂";
            position: absolute;
            left: 0;
            color: #667eea;
        }

        .section {
            margin-bottom: 40px;
            padding: 30px;
            background: #f8f9fa;
            border-radius: 15px;
            border-left: 5px solid #667eea;
        }

        .section h2 {
            color: #667eea;
            font-size: 1.8em;
            margin-bottom: 20px;
            font-weight: 600;
        }

        .section h3 {
            color: #764ba2;
            font-size: 1.4em;
            margin-bottom: 15px;
            margin-top: 25px;
        }

        .neuron-diagram {
            text-align: center;
            margin: 30px 0;
            padding: 25px;
            background: white;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }

        .formula {
            background: #2d3748;
            color: #e2e8f0;
            padding: 20px;
            border-radius: 10px;
            font-family: 'Courier New', monospace;
            font-size: 1.1em;
            margin: 20px 0;
            overflow-x: auto;
        }

        .activation-visual {
            display: flex;
            justify-content: space-around;
            margin: 25px 0;
            flex-wrap: wrap;
        }

        .activation-box {
            background: white;
            padding: 20px;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            text-align: center;
            margin: 10px;
            min-width: 200px;
        }

        .network-architecture {
            display: flex;
            justify-content: center;
            align-items: center;
            margin: 30px 0;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }

        .layer {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin: 0 30px;
        }

        .neuron {
            width: 40px;
            height: 40px;
            border-radius: 50%;
            background: #667eea;
            margin: 10px 0;
            display: flex;
            align-items: center;
            justify-content: center;
            color: white;
            font-weight: bold;
            box-shadow: 0 4px 10px rgba(0,0,0,0.2);
        }

        .connection {
            width: 50px;
            height: 2px;
            background: #ccc;
            margin: 0 10px;
        }

        .xor-table {
            margin: 20px auto;
            border-collapse: collapse;
            background: white;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        }

        .xor-table th, .xor-table td {
            border: 1px solid #ddd;
            padding: 15px;
            text-align: center;
        }

        .xor-table th {
            background: #667eea;
            color: white;
            font-weight: 600;
        }

        .highlight {
            background: #fff3cd;
            padding: 20px;
            border-left: 4px solid #ffc107;
            border-radius: 5px;
            margin: 20px 0;
        }

        .key-points {
            background: #d4edda;
            border: 1px solid #c3e6cb;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
        }

        .key-points h3 {
            color: #155724;
            margin-bottom: 15px;
        }

        .key-points ul {
            list-style-type: none;
            padding-left: 0;
        }

        .key-points li {
            margin-bottom: 10px;
            padding-left: 25px;
            position: relative;
        }

        .key-points li::before {
            content: "‚úÖ";
            position: absolute;
            left: 0;
        }

        .gradient-descent {
            background: linear-gradient(90deg, #ff6b6b, #feca57, #48dbfb, #0abde3);
            height: 20px;
            border-radius: 10px;
            margin: 20px 0;
            position: relative;
        }

        .gradient-descent::after {
            content: "Descente de gradient";
            position: absolute;
            top: 25px;
            left: 50%;
            transform: translateX(-50%);
            font-size: 0.9em;
            color: #666;
        }

        .math-box {
            background: #f1f3f4;
            border: 2px solid #667eea;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
            text-align: center;
        }

        .example-box {
            background: #e8f4f8;
            border: 2px solid #17a2b8;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
        }

        .example-box h4 {
            color: #17a2b8;
            margin-bottom: 15px;
        }

        .print-button {
            position: fixed;
            bottom: 20px;
            right: 20px;
            background: #667eea;
            color: white;
            border: none;
            padding: 15px 20px;
            border-radius: 50px;
            cursor: pointer;
            font-size: 1em;
            font-weight: 600;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
            transition: all 0.3s ease;
        }

        .print-button:hover {
            background: #764ba2;
            transform: translateY(-2px);
        }

        @media print {
            body {
                background: white;
            }
            .container {
                box-shadow: none;
                margin: 0;
            }
            .print-button {
                display: none;
            }
        }

        .architecture-types {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }

        .architecture-card {
            background: white;
            padding: 25px;
            border-radius: 10px;
            box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            border-top: 4px solid #667eea;
        }

        .loss-function {
            background: #fff5f5;
            border: 2px solid #e53e3e;
            padding: 20px;
            border-radius: 10px;
            margin: 20px 0;
        }

        .loss-function h4 {
            color: #e53e3e;
            margin-bottom: 15px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üìò Guide Visuel des R√©seaux de Neurones</h1>
            <p>Une introduction compl√®te et illustr√©e aux r√©seaux de neurones artificiels</p>
        </div>

        <div class="toc">
            <h2>üìã Table des mati√®res</h2>
            <ul>
                <li>1. Introduction aux r√©seaux de neurones</li>
                <li>2. Anatomie d'un neurone artificiel</li>
                <li>3. Fonctions d'activation essentielles</li>
                <li>4. Architecture des r√©seaux</li>
                <li>5. Types de r√©seaux de neurones</li>
                <li>6. Processus d'apprentissage</li>
                <li>7. Fonctions de perte</li>
                <li>8. Exemple pratique : XOR</li>
                <li>9. Optimisation et hyperparam√®tres</li>
                <li>10. Applications pratiques</li>
                <li>11. Bonnes pratiques</li>
                <li>12. R√©sum√© et points cl√©s</li>
            </ul>
        </div>

        <div class="section">
            <h2>üß† 1. Introduction aux r√©seaux de neurones</h2>
            <p>Un r√©seau de neurones artificiel est un mod√®le computationnel inspir√© du fonctionnement du cerveau humain. Il est compos√© d'unit√©s de traitement simples appel√©es <strong>neurones artificiels</strong>, organis√©es en couches interconnect√©es.</p>
            
            <div class="neuron-diagram">
                <h3>Sch√©ma d'un neurone biologique vs artificiel</h3>
                <div style="display: flex; justify-content: space-around; margin-top: 20px;">
                    <div style="text-align: center;">
                        <h4>Neurone biologique</h4>
                        <div style="font-size: 2em; margin: 20px 0;">üß†</div>
                        <p>Dendrites ‚Üí Corps cellulaire ‚Üí Axone</p>
                    </div>
                    <div style="text-align: center;">
                        <h4>Neurone artificiel</h4>
                        <div style="font-size: 2em; margin: 20px 0;">‚ö°</div>
                        <p>Entr√©es ‚Üí Fonction ‚Üí Sortie</p>
                    </div>
                </div>
            </div>

            <div class="highlight">
                <strong>Analogie :</strong> Comme le cerveau traite l'information √† travers des r√©seaux de neurones interconnect√©s, les r√©seaux de neurones artificiels traitent les donn√©es √† travers des couches de calculs math√©matiques.
            </div>
        </div>

        <div class="section">
            <h2>‚öôÔ∏è 2. Anatomie d'un neurone artificiel</h2>
            
            <div class="neuron-diagram">
                <h3>Structure d√©taill√©e d'un neurone</h3>
                <div style="font-family: monospace; font-size: 1.1em; margin: 20px 0;">
                    <pre>
    x‚ÇÅ ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ    w‚ÇÅ
    x‚ÇÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚Üí [Œ£] ‚îÄ‚îÄ‚Üí [f] ‚îÄ‚îÄ‚Üí y
           ‚îÇ    w‚ÇÇ      +b
    x‚ÇÉ ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           w‚ÇÉ
                    </pre>
                </div>
            </div>

            <div class="formula">
z = w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + w‚ÇÉx‚ÇÉ + b
y = f(z)
            </div>

            <h3>Composants principaux :</h3>
            <div class="architecture-types">
                <div class="architecture-card">
                    <h4>üî¢ Entr√©es (x)</h4>
                    <p>Les donn√©es d'entr√©e ou les sorties des neurones pr√©c√©dents. Chaque entr√©e repr√©sente une caract√©ristique (feature) des donn√©es.</p>
                </div>
                <div class="architecture-card">
                    <h4>‚öñÔ∏è Poids (w)</h4>
                    <p>Param√®tres appris qui d√©terminent l'importance de chaque entr√©e. Plus le poids est √©lev√©, plus l'influence est grande.</p>
                </div>
                <div class="architecture-card">
                    <h4>‚ûï Biais (b)</h4>
                    <p>Param√®tre additionnel qui permet de d√©caler la fonction d'activation. Il agit comme un seuil d'activation.</p>
                </div>
                <div class="architecture-card">
                    <h4>üéØ Fonction d'activation (f)</h4>
                    <p>Fonction non-lin√©aire qui transforme la somme pond√©r√©e en sortie du neurone.</p>
                </div>
            </div>

            <div class="example-box">
                <h4>üí° Exemple concret</h4>
                <p>Pr√©diction du prix d'une maison :</p>
                <ul>
                    <li>x‚ÇÅ = surface (m¬≤)</li>
                    <li>x‚ÇÇ = nombre de chambres</li>
                    <li>x‚ÇÉ = √¢ge de la maison</li>
                    <li>w‚ÇÅ = 1000 (‚Ç¨/m¬≤)</li>
                    <li>w‚ÇÇ = 5000 (‚Ç¨/chambre)</li>
                    <li>w‚ÇÉ = -500 (‚Ç¨/ann√©e)</li>
                    <li>b = 50000 (‚Ç¨, prix de base)</li>
                </ul>
            </div>
        </div>

        <div class="section">
            <h2>üìä 3. Fonctions d'activation essentielles</h2>
            <p>Les fonctions d'activation introduisent la non-lin√©arit√© dans le r√©seau, permettant d'apprendre des relations complexes.</p>

            <div class="activation-visual">
                <div class="activation-box">
                    <h4>ReLU (Rectified Linear Unit)</h4>
                    <div class="formula">f(x) = max(0, x)</div>
                    <p><strong>Avantages :</strong> Simple, rapide, √©vite le gradient vanishing</p>
                    <p><strong>Inconv√©nients :</strong> Neurones "morts" pour x &lt; 0</p>
                </div>
                
                <div class="activation-box">
                    <h4>Sigmo√Øde</h4>
                    <div class="formula">f(x) = 1/(1 + e^(-x))</div>
                    <p><strong>Avantages :</strong> Sortie entre 0 et 1, interpr√©table comme probabilit√©</p>
                    <p><strong>Inconv√©nients :</strong> Gradient vanishing, saturation</p>
                </div>
                
                <div class="activation-box">
                    <h4>Tanh</h4>
                    <div class="formula">f(x) = (e^x - e^(-x))/(e^x + e^(-x))</div>
                    <p><strong>Avantages :</strong> Sortie entre -1 et 1, centr√©e sur 0</p>
                    <p><strong>Inconv√©nients :</strong> Gradient vanishing aux extr√™mes</p>
                </div>
            </div>

            <div class="activation-visual">
                <div class="activation-box">
                    <h4>Leaky ReLU</h4>
                    <div class="formula">f(x) = max(0.01x, x)</div>
                    <p><strong>Avantages :</strong> √âvite les neurones morts</p>
                    <p><strong>Usage :</strong> Alternative √† ReLU</p>
                </div>
                
                <div class="activation-box">
                    <h4>Softmax</h4>
                    <div class="formula">f(x_i) = e^(x_i) / Œ£e^(x_j)</div>
                    <p><strong>Avantages :</strong> Parfait pour classification multi-classes</p>
                    <p><strong>Usage :</strong> Couche de sortie</p>
                </div>
                
                <div class="activation-box">
                    <h4>Swish</h4>
                    <div class="formula">f(x) = x * sigmoid(x)</div>
                    <p><strong>Avantages :</strong> Auto-gating, performance sup√©rieure</p>
                    <p><strong>Usage :</strong> R√©seaux profonds modernes</p>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>üèóÔ∏è 4. Architecture des r√©seaux</h2>
            
            <div class="network-architecture">
                <div class="layer">
                    <h4>Couche d'entr√©e</h4>
                    <div class="neuron">x‚ÇÅ</div>
                    <div class="neuron">x‚ÇÇ</div>
                    <div class="neuron">x‚ÇÉ</div>
                    <div class="neuron">x‚ÇÑ</div>
                </div>
                
                <div class="connection"></div>
                
                <div class="layer">
                    <h4>Couche cach√©e 1</h4>
                    <div class="neuron">h‚ÇÅ</div>
                    <div class="neuron">h‚ÇÇ</div>
                    <div class="neuron">h‚ÇÉ</div>
                    <div class="neuron">h‚ÇÑ</div>
                    <div class="neuron">h‚ÇÖ</div>
                </div>
                
                <div class="connection"></div>
                
                <div class="layer">
                    <h4>Couche cach√©e 2</h4>
                    <div class="neuron">h‚ÇÅ</div>
                    <div class="neuron">h‚ÇÇ</div>
                    <div class="neuron">h‚ÇÉ</div>
                </div>
                
                <div class="connection"></div>
                
                <div class="layer">
                    <h4>Couche de sortie</h4>
                    <div class="neuron">y‚ÇÅ</div>
                    <div class="neuron">y‚ÇÇ</div>
                </div>
            </div>

            <div class="math-box">
                <h4>Repr√©sentation matricielle</h4>
                <div class="formula">
H‚ÇÅ = f‚ÇÅ(W‚ÇÅ √ó X + b‚ÇÅ)
H‚ÇÇ = f‚ÇÇ(W‚ÇÇ √ó H‚ÇÅ + b‚ÇÇ)
Y = f‚ÇÉ(W‚ÇÉ √ó H‚ÇÇ + b‚ÇÉ)
                </div>
            </div>
        </div>

        <div class="section">
            <h2>üîÑ 5. Types de r√©seaux de neurones</h2>
            
            <div class="architecture-types">
                <div class="architecture-card">
                    <h4>üîó Perceptron Multi-Couches (MLP)</h4>
                    <p>R√©seau enti√®rement connect√© avec propagation avant. Id√©al pour les probl√®mes de classification et r√©gression sur donn√©es tabulaires.</p>
                    <p><strong>Usage :</strong> Donn√©es structur√©es, probl√®mes simples</p>
                </div>
                
                <div class="architecture-card">
                    <h4>üñºÔ∏è R√©seaux de Neurones Convolutionnels (CNN)</h4>
                    <p>Sp√©cialis√©s dans le traitement d'images avec des couches de convolution et pooling.</p>
                    <p><strong>Usage :</strong> Vision par ordinateur, traitement d'images</p>
                </div>
                
                <div class="architecture-card">
                    <h4>üîÑ R√©seaux de Neurones R√©currents (RNN)</h4>
                    <p>Poss√®dent une m√©moire pour traiter des s√©quences de donn√©es.</p>
                    <p><strong>Usage :</strong> Traitement du langage, s√©ries temporelles</p>
                </div>
                
                <div class="architecture-card">
                    <h4>üß† LSTM/GRU</h4>
                    <p>Versions am√©lior√©es des RNN qui g√®rent mieux les d√©pendances √† long terme.</p>
                    <p><strong>Usage :</strong> Traduction, g√©n√©ration de texte</p>
                </div>
                
                <div class="architecture-card">
                    <h4>üéØ Transformers</h4>
                    <p>Architecture bas√©e sur les m√©canismes d'attention, r√©volutionnant le NLP.</p>
                    <p><strong>Usage :</strong> GPT, BERT, traduction automatique</p>
                </div>
                
                <div class="architecture-card">
                    <h4>üé® Autoencodeurs</h4>
                    <p>R√©seaux qui apprennent √† compresser et reconstruire les donn√©es.</p>
                    <p><strong>Usage :</strong> R√©duction de dimensionnalit√©, d√©tection d'anomalies</p>
                </div>
            </div>
        </div>

        <div class="section">
            <h2>üìà 6. Processus d'apprentissage</h2>
            
            <div class="neuron-diagram">
                <h3>Cycle d'apprentissage</h3>
                <div style="display: flex; justify-content: space-around; margin: 30px 0;">
                    <div style="text-align: center; max-width: 200px;">
                        <div style="font-size: 2em; margin: 10px 0;">‚û°Ô∏è</div>
                        <h4>1. Propagation avant</h4>
                        <p>Calcul des pr√©dictions</p>
                    </div>
                    <div style="text-align: center; max-width: 200px;">
                        <div style="font-size: 2em; margin: 10px 0;">üìä</div>
                        <h4>2. Calcul de la perte</h4>
                        <p>Mesure de l'erreur</p>
                    </div>
                    <div style="text-align: center; max-width: 200px;">
                        <div style="font-size: 2em; margin: 10px 0;">‚¨ÖÔ∏è</div>
                        <h4>3. R√©tropropagation</h4>
                        <p>Calcul des gradients</p>
                    </div>
                    <div style="text-align: center; max-width: 200px;">
                        <div style="font-size: 2em; margin: 10px 0;">üîÑ</div>
                        <h4>4. Mise √† jour</h4>
                        <p>Optimisation des poids</p>
                    </div>
                </div>
            </div>

            <h3>Algorithme de r√©tropropagation</h3>
            <div class="formula">
# Propagation avant
z^(l) = W^(l) √ó a^(l-1) + b^(l)
a^(l) = f(z^(l))

# R√©tropropagation
Œ¥^(L) = ‚àá_a C ‚äô f'(z^(L))
Œ¥^(l) = ((W^(l+1))^T Œ¥^(l+1)) ‚äô f'(z^(l))

# Mise √† jour des poids
W^(l) = W^(l) - Œ∑ √ó Œ¥^(l) √ó (a^(l-1))^T
b^(l) = b^(l) - Œ∑ √ó Œ¥^(l)
            </div>

            <div class="gradient-descent"></div>
        </div>

        <div class="section">
            <h2>üìâ 7. Fonctions de perte</h2>
            
            <div class="loss-function">
                <h4>Classification binaire - Entropie crois√©e</h4>
                <div class="formula">L = -[y√ólog(≈∑) + (1-y)√ólog(1-≈∑)]</div>
                <p>Utilis√©e quand la sortie est une probabilit√© entre 0 et 1.</p>
            </div>
            
            <div class="loss-function">
                <h4>Classification multi-classes - Entropie crois√©e cat√©gorielle</h4>
                <div class="formula">L = -Œ£(y_i √ó log(≈∑_i))</div>
                <p>Utilis√©e avec softmax pour les probl√®mes multi-classes.</p>
            </div>
            
            <div class="loss-function">
                <h4>R√©gression - Erreur quadratique moyenne (MSE)</h4>
                <div class="formula">L = (1/n) √ó Œ£(y_i - ≈∑_i)¬≤</div>
                <p>Mesure la diff√©rence quadratique entre pr√©dictions et valeurs r√©elles.</p>
            </div>
            
            <div class="loss-function">
                <h4>R√©gression robuste - Erreur absolue moyenne (MAE)</h4>
                <div class="formula">L = (1/n) √ó Œ£|y_i - ≈∑_i|</div>
                <p>Moins sensible aux valeurs aberrantes que MSE.</p>
            </div>
        </div>

        <div class="section">
            <h2>üîÄ 8. Exemple pratique : Le probl√®me XOR</h2>
            <p>Le XOR est un probl√®me classique qui d√©montre l'importance des couches cach√©es pour r√©soudre des probl√®mes non-lin√©aires.</p>
            
            <table class="xor-table">
                <thead>
                    <tr>
                        <th>x‚ÇÅ</th>
                        <th>x‚ÇÇ</th>
                        <th>XOR (y)</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td>0</td>
                        <td>0</td>
                        <td>0</td>
                    </tr>
                    <tr>
                        <td>0</td>
                        <td>1</td>
                        <td>1</td>
                    </tr>
                    <tr>
                        <td>1</td>
                        <td>0</td>
                        <td>1</td>
                    </tr>
                    <tr>
                        <td>1</td>
                        <td>1</td>
                        <td>0</td>
                    </tr>
                </tbody>
            </table>

            <div class="highlight">
                <strong>Probl√®me :</strong> Un perceptron simple (sans couche cach√©e) ne peut pas r√©soudre XOR car ce n'est pas lin√©airement s√©parable.
            </div>

            <div class="network-architecture">
                <div class="layer">
                    <h4>Entr√©e</h4>
                    <div class="neuron">x‚ÇÅ</div>
                    <div class="neuron">x‚ÇÇ</div>
                </div>
                
                <div class="connection"></div>
                
                <div class="layer">
                    <h4>Cach√©e</h4>
                    <div class="neuron">h‚ÇÅ</div>
                    <div class="neuron">h‚ÇÇ</div>
                </div>
                
                <div class="connection"></div>
                
                <div class="layer">
                    <h4>Sortie</h4>
                    <div class="neuron">y</div>
                </div>
            </div>

            <div class="example-box">
                <h4>üí° Solution avec couche cach√©e</h4>
                <p>La couche cach√©e permet de transformer l'espace d'entr√©e pour rendre le probl√®me lin√©airement s√©parable :</p>
                <ul>
                    <li>h‚ÇÅ apprend √† d√©tecter "x‚ÇÅ ET x‚ÇÇ"</li>
                    <li